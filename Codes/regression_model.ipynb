{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3d(x, W):\n",
    "    return tf.nn.conv3d(x, W, strides=[1,1,1,1,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool3d(x):\n",
    "    #                        size of window         movement of window\n",
    "    return tf.nn.max_pool3d(x, ksize=[1,2,2,2,1], strides=[1,2,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_neural_network(x):\n",
    "    initializer = tf.contrib.layers.xavier_initializer()\n",
    "    weights = {'W_conv1':tf.Variable(initializer([3,3,3,1,8]), name=\"W_conv1\"),\n",
    "               'W_conv2':tf.Variable(initializer([3,3,3,8,16]), name=\"W_conv2\"),\n",
    "               'W_conv3':tf.Variable(initializer([3,3,3,16,32]), name=\"W_conv3\"),\n",
    "               'W_conv4':tf.Variable(initializer([3,3,3,32,64]), name=\"W_conv4\"),\n",
    "               'W_conv5':tf.Variable(initializer([3,3,3,64,128]), name=\"W_conv5\"),\n",
    "               'W_fc':tf.Variable(initializer([2304,1024]), name=\"W_fc\"),\n",
    "               'W_out':tf.Variable(initializer([1024, n_classes]), name=\"W_out\")}\n",
    "\n",
    "    biases = {'b_conv1':tf.Variable(initializer([8]), name=\"b_conv1\"),\n",
    "               'b_conv2':tf.Variable(initializer([16]), name=\"b_conv2\"),\n",
    "              'b_conv3':tf.Variable(initializer([32]), name=\"b_conv3\"),\n",
    "              'b_conv4':tf.Variable(initializer([64]), name=\"b_conv4\"),\n",
    "              'b_conv5':tf.Variable(initializer([128]), name=\"b_conv5\"),\n",
    "               'b_fc':tf.Variable(initializer([1024]), name=\"b_fc\"),\n",
    "               'b_out':tf.Variable(initializer([n_classes]), name=\"b_out\")}\n",
    "\n",
    "    x = tf.reshape(x, shape=[-1, IMG_SIZE_PX, IMG_SIZE_PX, SLICE_COUNT, 1])\n",
    "\n",
    "    conv1 = tf.nn.relu(conv3d(x, weights['W_conv1']) + biases['b_conv1'])\n",
    "    conv1 = tf.nn.dropout(conv1, dropout_rate)\n",
    "    conv1 = maxpool3d(conv1)\n",
    "    \n",
    "    conv2 = tf.nn.relu(conv3d(conv1, weights['W_conv2']) + biases['b_conv2'])\n",
    "    conv2 = tf.nn.dropout(conv2, dropout_rate)\n",
    "    conv2 = maxpool3d(conv2)\n",
    "\n",
    "    conv3 = tf.nn.relu(conv3d(conv2, weights['W_conv3']) + biases['b_conv3'])\n",
    "    conv3 = tf.nn.dropout(conv3, dropout_rate)\n",
    "    conv3 = maxpool3d(conv3)\n",
    "\n",
    "    conv4 = tf.nn.relu(conv3d(conv3, weights['W_conv4']) + biases['b_conv4'])\n",
    "    conv4 = tf.nn.dropout(conv4, dropout_rate)\n",
    "    conv4 = maxpool3d(conv4)\n",
    "\n",
    "    conv5 = tf.nn.relu(conv3d(conv4, weights['W_conv5']) + biases['b_conv5'])\n",
    "    conv5 = tf.nn.dropout(conv5, dropout_rate)\n",
    "    conv5 = maxpool3d(conv5)\n",
    "    \n",
    "\n",
    "    fc = tf.reshape(conv5,[-1, 2304])\n",
    "    #fc = tf.nn.relu(tf.matmul(fc, weights['W_fc'])+biases['b_fc'])\n",
    "    fc = tf.matmul(fc, weights['W_fc'])+biases['b_fc']\n",
    "    fc = tf.nn.dropout(fc, dropout_rate)\n",
    "\n",
    "    output = tf.add(tf.matmul(fc, weights['W_out']),biases['b_out'],name=\"output\")\n",
    "\n",
    "    return output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network(x):\n",
    "\n",
    "    \n",
    "    prediction = convolutional_neural_network(x)\n",
    "    cost = tf.reduce_mean(tf.square(prediction-y),name=\"cost\")\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    #accuracy = tf.contrib.metrics.streaming_pearson_correlation(prediction, tf.cast(y,tf.float32))[0]\n",
    "    saver = tf.train.Saver(save_relative_paths=True)\n",
    "    \n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "\n",
    "        for epoch in range(hm_epochs):\n",
    "            avg_cost = 0.\n",
    "            \n",
    "            index = [ind for ind in range(1,train_batch+1)]\n",
    "            original = index[:]\n",
    "            random.shuffle(index)\n",
    "            \n",
    "            for original_index in range (1, train_batch+1):\n",
    "                current_batch = index[original_index-1]\n",
    "                batch_data = np.load(folder + 'batch({},{})-{}-{}-{}.npy'.format(current_batch*batch_size+1,\n",
    "                                    current_batch*batch_size+batch_size,IMG_SIZE_PX,IMG_SIZE_PX,SLICE_COUNT))\n",
    "\n",
    "                for data in batch_data:\n",
    "                    X = data[0]\n",
    "                    Y = data[1]\n",
    "                    _, c, p = sess.run([optimizer, cost, prediction], feed_dict={x: X, y: Y})\n",
    "                    avg_cost += c / (train_batch * batch_size)\n",
    "\n",
    "            print('Epoch', epoch+1, 'completed out of',hm_epochs,'cost:',avg_cost)\n",
    "            \n",
    "            avg_valicost = 0.\n",
    "            pred_matrix = np.array([]).reshape(0,1)\n",
    "            label_matrix = np.array([]).reshape(0,1)\n",
    "            for current_validation in range (train_batch, train_batch+validation_batch):\n",
    "                validation_data = np.load(folder + 'batch({},{})-{}-{}-{}.npy'.format(current_validation*batch_size+1,\n",
    "                                            current_validation*batch_size+batch_size,IMG_SIZE_PX,IMG_SIZE_PX,SLICE_COUNT))\n",
    "                for data in validation_data:\n",
    "                    c, predict_value = sess.run([cost, prediction], feed_dict={x:data[0], y:data[1]})\n",
    "                    predict_value = predict_value.reshape(1,1)\n",
    "                    avg_valicost += c / (validation_batch * batch_size)\n",
    "                    label_value = data[1].reshape(1,1)\n",
    "                    pred_matrix=np.concatenate((pred_matrix, predict_value), axis=0)\n",
    "                    label_matrix=np.concatenate((label_matrix, label_value), axis=0)\n",
    "                    \n",
    "            print(\"avgvalicost\", avg_valicost)\n",
    "            print(np.concatenate((pred_matrix.T, label_matrix.T),axis=0).shape)\n",
    "            evaluated_accuracy = np.corrcoef(np.concatenate((pred_matrix.T, label_matrix.T), axis=0))\n",
    "            print('pearson:',evaluated_accuracy)\n",
    "\n",
    "            if ((epoch+1)%epoch_save==0):\n",
    "                filename = '/home/lvruyi/regression_small_epoch_' + str(epoch+1)\n",
    "                saver.save(sess, filename)\n",
    "                test_data = np.load(folder + 'batch(1473,1482)-65-65-55.npy')\n",
    "                #test_data = np.load(folder + 'batch(2065,2072)-65-65-55.npy')\n",
    "                for tdata in test_data:\n",
    "                    label_value = tdata[1]\n",
    "                    predicted_value = sess.run(prediction, feed_dict={x: tdata[0], y:tdata[1]})\n",
    "                    print (\"label value:\", label_value, \";    estimated value:\", predicted_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE_PX = 65\n",
    "SLICE_COUNT = 55\n",
    "n_classes = 1\n",
    "#train_batch = 15\n",
    "train_batch = 75\n",
    "batch_size = 16\n",
    "#validation_batch = 4\n",
    "validation_batch = 17\n",
    "labels_file = pd.read_csv('FYP_Phenotypic2noxrotate.csv')\n",
    "\n",
    "tf.reset_default_graph()\n",
    "x = tf.placeholder('float',name=\"x\")\n",
    "y = tf.placeholder('float',name=\"y\")\n",
    "\n",
    "learning_rate = 0.00007\n",
    "dropout_rate = 0.8\n",
    "hm_epochs = 20000\n",
    "epoch_save= 5\n",
    "#\"combined2\\\\\"\n",
    "folder = '/home/lvruyi/combined2noxrotate/'\n",
    "\n",
    "#calculate_mean()`\n",
    "\n",
    "#shuffle()\n",
    "\n",
    "\"\"\"\n",
    "for batch in range (0, train_batch+validation_batch-1):\n",
    "    combine_preprocess(batch*batch_size+1, batch*batch_size+batch_size)\n",
    "\n",
    "combine_preprocess(2065, 2072)\n",
    "\"\"\"\n",
    "                                     \n",
    "train_neural_network(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
